{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4cba5bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from google.adk.agents import Agent\n",
    "import pandas as pd\n",
    "from google.genai.types import GenerateContentConfig\n",
    "import os.path\n",
    "import datetime\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "import uuid\n",
    "from google.adk.agents import Agent\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Tuple\n",
    "import logging\n",
    "import html\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "import io\n",
    "from typing import List, Dict, Optional, Any\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Scopes: Drive, Docs, YouTube (as you used before)\n",
    "SCOPES = [\n",
    "    \"https://www.googleapis.com/auth/drive\",\n",
    "    \"https://www.googleapis.com/auth/youtube.force-ssl\",\n",
    "]\n",
    "\n",
    "TOKEN_FILE = \"./token.json\"\n",
    "CREDENTIALS_FILE = \"./credentials.json\"\n",
    "\n",
    "\n",
    "def get_credentials(scopes=SCOPES) -> Credentials:\n",
    "    \"\"\"\n",
    "    Obtain OAuth2 credentials, refreshing or running a local flow if needed.\n",
    "    Returns valid Credentials instance.\n",
    "    \"\"\"\n",
    "    creds = None\n",
    "    if os.path.exists(TOKEN_FILE):\n",
    "        creds = Credentials.from_authorized_user_file(TOKEN_FILE, scopes)\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            if not os.path.exists(CREDENTIALS_FILE):\n",
    "                raise FileNotFoundError(f\"OAuth credentials file not found: {CREDENTIALS_FILE}\")\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(CREDENTIALS_FILE, scopes)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        with open(TOKEN_FILE, \"w\", encoding=\"utf-8\") as token:\n",
    "            token.write(creds.to_json())\n",
    "    return creds\n",
    "\n",
    "\n",
    "def normalize(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize a search string: remove excessive punctuation while keeping Korean/English/nums and spaces.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    # Keep Hangul, basic Latin, digits and spaces. Replace other characters with space.\n",
    "    cleaned = re.sub(r\"[^0-9A-Za-z가-힣\\s]\", \" \", text)\n",
    "    # collapse whitespace\n",
    "    cleaned = re.sub(r\"\\s+\", \" \", cleaned).strip()\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "def preview_youtube_playlist(playlist_id: str):\n",
    "    \"\"\"\n",
    "    Fetch a YouTube playlist and return list of {'video_id', 'title'}.\n",
    "    \"\"\"\n",
    "    creds = get_credentials()\n",
    "    youtube = build(\"youtube\", \"v3\", credentials=creds)\n",
    "\n",
    "    videos: List[Dict[str, str]] = []\n",
    "    next_page_token = None\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            req = youtube.playlistItems().list(\n",
    "                part=\"snippet\",\n",
    "                playlistId=playlist_id,\n",
    "                maxResults=50,\n",
    "                pageToken=next_page_token,\n",
    "            )\n",
    "            res = req.execute()\n",
    "            for item in res.get(\"items\", []):\n",
    "                vid = item[\"snippet\"][\"resourceId\"].get(\"videoId\")\n",
    "                title = item[\"snippet\"].get(\"title\", \"\")\n",
    "                videos.append({\"video_id\": vid, \"title\": title})\n",
    "            next_page_token = res.get(\"nextPageToken\")\n",
    "            if not next_page_token:\n",
    "                break\n",
    "        return videos\n",
    "    except HttpError as e:\n",
    "        logging.error(f\"YouTube API error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def read_google_doc(docs_service, document_id: str):\n",
    "    \"\"\"\n",
    "    Read a Google Doc's textual content and return plain text.\n",
    "    \"\"\"\n",
    "    doc = docs_service.documents().get(documentId=document_id).execute()\n",
    "    body = doc.get(\"body\", {}).get(\"content\", [])\n",
    "    out = []\n",
    "    for structural_element in body:\n",
    "        # Paragraphs and tables can contain text runs\n",
    "        paragraph = structural_element.get(\"paragraph\")\n",
    "        if paragraph:\n",
    "            text_run_parts = []\n",
    "            for el in paragraph.get(\"elements\", []):\n",
    "                tr = el.get(\"textRun\")\n",
    "                if tr and tr.get(\"content\"):\n",
    "                    text_run_parts.append(tr[\"content\"])\n",
    "            if text_run_parts:\n",
    "                out.append(\"\".join(text_run_parts))\n",
    "        # You could expand to table cells etc. if needed\n",
    "    return \"\\n\".join(out).strip()\n",
    "\n",
    "\n",
    "def read_drive_file(drive_service, file_id: str, mime_type: Optional[str]):\n",
    "    \"\"\"\n",
    "    Read a file from Drive:\n",
    "    - If Google Doc, use Docs API (caller must provide credentials or build docs_service separately).\n",
    "    - If text/plain, download raw media.\n",
    "    \"\"\"\n",
    "    if mime_type == \"application/vnd.google-apps.document\":\n",
    "        docs_service = build(\"docs\", \"v1\", credentials=get_credentials())\n",
    "        return read_google_doc(docs_service, file_id)\n",
    "    else:\n",
    "        # Attempt to download file contents (works for .txt and other binary types; we decode as utf-8)\n",
    "        try:\n",
    "            request = drive_service.files().get_media(fileId=file_id)\n",
    "            fh = io.BytesIO()\n",
    "            downloader = MediaIoBaseDownload(fh, request)\n",
    "            done = False\n",
    "            while not done:\n",
    "                status, done = downloader.next_chunk()\n",
    "            fh.seek(0)\n",
    "            data = fh.read()\n",
    "            # try decode, fallback to latin-1 if necessary\n",
    "            try:\n",
    "                return data.decode(\"utf-8\")\n",
    "            except UnicodeDecodeError:\n",
    "                try:\n",
    "                    return data.decode(\"utf-8-sig\")\n",
    "                except Exception:\n",
    "                    return data.decode(\"latin-1\", errors=\"ignore\")\n",
    "        except HttpError as e:\n",
    "            logging.error(f\"Error downloading file {file_id}: {e}\")\n",
    "            return None\n",
    "\n",
    "\n",
    "def find_files_by_name(\n",
    "    search_name: str, folder_id = '1hiSf6DSAO2RIv7ZCT7ltU8uBYQFvaOQu', page_size: int = 20\n",
    "):\n",
    "    \"\"\"\n",
    "    Find files in Google Drive that match a search string.\n",
    "    Returns list of file dicts: [{'id','name','mimeType','snippet'(optional)}...]\n",
    "    Tries name contains to match content inside Google Docs.\n",
    "    \"\"\"\n",
    "    creds = get_credentials()\n",
    "    drive_service = build(\"drive\", \"v3\", credentials=creds)\n",
    "\n",
    "    clean = normalize(search_name)\n",
    "    # Build query safely. Use either name or fullText match\n",
    "    q_parts = []\n",
    "    if clean:\n",
    "        # escape single quotes by replacing with \\'\n",
    "        clean_escaped = clean.replace(\"'\", \"\\\\'\")\n",
    "        q_parts.append(f\"name contains '{clean_escaped}'\")\n",
    "    else:\n",
    "        q_parts.append(\"trashed=false\")\n",
    "\n",
    "    q_parts.append(\"trashed=false\")\n",
    "    if folder_id:\n",
    "        q_parts.append(f\"'{folder_id}' in parents\")\n",
    "\n",
    "    query = \" and \".join(q_parts)\n",
    "\n",
    "    try:\n",
    "        results = drive_service.files().list(\n",
    "            q=query,\n",
    "            spaces=\"drive\",\n",
    "            fields=\"nextPageToken, files(id, name, mimeType)\",\n",
    "            pageSize=page_size,\n",
    "        ).execute()\n",
    "        items = results.get(\"files\", [])\n",
    "        if not items:\n",
    "            return None\n",
    "\n",
    "        # Attach snippet/content for each item if possible (read small snippets only)\n",
    "        out = []\n",
    "        for item in items:\n",
    "            file_id = item[\"id\"]\n",
    "            mime = item.get(\"mimeType\")\n",
    "            # Read the file content (full) if it's reasonable; caller can choose\n",
    "            content = None\n",
    "            try:\n",
    "                content = read_drive_file(drive_service, file_id, mime)\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"Could not read content for {file_id}: {e}\")\n",
    "            out.append({\"id\": file_id, \"name\": item.get(\"name\"), \"mimeType\": mime, \"content\": content})\n",
    "        return out\n",
    "    except HttpError as e:\n",
    "        logging.error(f\"Drive API error during search: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def drive_save_lyrics(lyrics_list: List[Dict[str, str]], folder_id = '1hiSf6DSAO2RIv7ZCT7ltU8uBYQFvaOQu'):\n",
    "    \"\"\"\n",
    "    Save each song's lyrics as a separate Google Doc in the given Drive folder.\n",
    "    Each doc will be named \"KoreanTitle / EnglishTitle\" (fall back to unique id).\n",
    "    lyrics_list entries should include keys:\n",
    "        - 'korean_title' or 'korean'\n",
    "        - 'english_title' or 'english'\n",
    "        - 'korean_lyrics' or 'korean'\n",
    "        - 'english_lyrics' or 'english'\n",
    "    Returns list of created file metadata [{'id', 'name'}]\n",
    "    \"\"\"\n",
    "    creds = get_credentials()\n",
    "    drive_service = build(\"drive\", \"v3\", credentials=creds)\n",
    "    docs_service = build(\"docs\", \"v1\", credentials=creds)\n",
    "\n",
    "    created_files = []\n",
    "\n",
    "    for entry in lyrics_list:\n",
    "        eng_title = entry.get(\"english_title\") or entry.get(\"english\") or \"\"\n",
    "        kor_title = entry.get(\"korean_title\") or entry.get(\"korean\") or \"\"\n",
    "        eng_lyrics = entry.get(\"english_lyrics\") or entry.get(\"english_lyrics\") or entry.get(\"english\") or \"\"\n",
    "        kor_lyrics = entry.get(\"korean_lyrics\") or entry.get(\"korean_lyrics\") or entry.get(\"korean\") or \"\"\n",
    "\n",
    "        name_parts = []\n",
    "        if kor_title.strip():\n",
    "            name_parts.append(kor_title.strip())\n",
    "        if eng_title.strip():\n",
    "            name_parts.append(eng_title.strip())\n",
    "\n",
    "        doc_name = \" / \".join(name_parts) if name_parts else f\"lyrics-{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "        try:\n",
    "            file_metadata = {\n",
    "                \"name\": doc_name,\n",
    "                \"mimeType\": \"application/vnd.google-apps.document\",\n",
    "            }\n",
    "            if folder_id:\n",
    "                file_metadata[\"parents\"] = [folder_id]\n",
    "\n",
    "            new_file = drive_service.files().create(body=file_metadata, fields=\"id,name\").execute()\n",
    "            doc_id = new_file.get(\"id\")\n",
    "\n",
    "            # Prepare content: english then korean (slide-by-slide style requested)\n",
    "            # We'll create a single ordered list: English Title -> English Lyrics -> Korean Title -> Korean Lyrics\n",
    "            # Break into lines and ensure we insert line-by-line to preserve structure\n",
    "            parts = []\n",
    "            if eng_title:\n",
    "                parts.append(f\"English Title: {eng_title}\")\n",
    "            if eng_lyrics:\n",
    "                parts.extend([line for line in eng_lyrics.splitlines()])\n",
    "            if kor_title:\n",
    "                parts.append(\"\")  # blank line separator\n",
    "                parts.append(f\"Korean Title: {kor_title}\")\n",
    "            if kor_lyrics:\n",
    "                parts.extend([line for line in kor_lyrics.splitlines()])\n",
    "\n",
    "            # Build batchUpdate requests: insert each line at increasing index\n",
    "            requests = []\n",
    "            # Insert at index 1 (start of doc). We'll insert a newline after each line so spacing is preserved.\n",
    "            cursor_index = 1\n",
    "            for idx, line in enumerate(parts):\n",
    "                # ensure each inserted chunk ends with newline (except maybe last — Docs handles final newline fine)\n",
    "                text_to_insert = f\"{line}\\n\"\n",
    "                requests.append({\"insertText\": {\"location\": {\"index\": cursor_index}, \"text\": text_to_insert}})\n",
    "                cursor_index += len(text_to_insert)\n",
    "\n",
    "            if requests:\n",
    "                docs_service.documents().batchUpdate(documentId=doc_id, body={\"requests\": requests}).execute()\n",
    "\n",
    "            created_files.append({\"id\": doc_id, \"name\": new_file.get(\"name\")})\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to create doc for '{doc_name}': {e}\")\n",
    "\n",
    "    return created_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2b81a82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_files_by_name(\"나를 통하여\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43e5209",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
